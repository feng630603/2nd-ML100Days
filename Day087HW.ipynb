{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Work\n",
    "請改變 reduce_lr 的 patience 和 factor 並比較不同設定下，對訓練/驗證集的影響\n",
    "請將 optimizer 換成 Adam、RMSprop 搭配 reduce_lr 並比較訓練結果\n",
    "'''\n",
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[256, 256, 256]):\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    return model\n",
    "'''\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "            x = BatchNormalization()(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 25 # IF you feel too run to finish, try to make it smaller\n",
    "BATCH_SIZE = 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 載入 Callbacks\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "optimizer_set = [keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=0.95),\n",
    "                 keras.optimizers.Adam(lr=LEARNING_RATE),\n",
    "                 keras.optimizers.RMSprop(lr=LEARNING_RATE)]\n",
    "\n",
    "\"\"\"Code Here\n",
    "建立實驗的比較組合\n",
    "\"\"\"\n",
    "reduce_lr_factor = [0.5, 0.1]\n",
    "redice_lr_patient = [5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of exp: 0, reduce_factor: 0.50, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 2.2230 - acc: 0.2758 - val_loss: 2.1168 - val_acc: 0.3156\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.7400 - acc: 0.3932 - val_loss: 1.8293 - val_acc: 0.3752\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.6071 - acc: 0.4381 - val_loss: 1.7085 - val_acc: 0.4099\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.5319 - acc: 0.4645 - val_loss: 1.6381 - val_acc: 0.4261\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4772 - acc: 0.4845 - val_loss: 1.5854 - val_acc: 0.4452\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.4312 - acc: 0.4994 - val_loss: 1.5599 - val_acc: 0.4489\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.3911 - acc: 0.5147 - val_loss: 1.5346 - val_acc: 0.4626\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.3555 - acc: 0.5295 - val_loss: 1.5207 - val_acc: 0.4652\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.3235 - acc: 0.5382 - val_loss: 1.5120 - val_acc: 0.4719\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.2959 - acc: 0.5493 - val_loss: 1.4916 - val_acc: 0.4759\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.2665 - acc: 0.5606 - val_loss: 1.4857 - val_acc: 0.4824\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.2404 - acc: 0.5703 - val_loss: 1.4837 - val_acc: 0.4696\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.2158 - acc: 0.5800 - val_loss: 1.4801 - val_acc: 0.4818\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 1.1910 - acc: 0.5899 - val_loss: 1.4784 - val_acc: 0.4799\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.1665 - acc: 0.5960 - val_loss: 1.4851 - val_acc: 0.4809\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 182us/step - loss: 1.1428 - acc: 0.6073 - val_loss: 1.4666 - val_acc: 0.4878\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.1206 - acc: 0.6157 - val_loss: 1.4473 - val_acc: 0.4907\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.0988 - acc: 0.6239 - val_loss: 1.4540 - val_acc: 0.4946\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.0763 - acc: 0.6320 - val_loss: 1.4582 - val_acc: 0.4894\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0562 - acc: 0.6393 - val_loss: 1.4495 - val_acc: 0.4980\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.0343 - acc: 0.6506 - val_loss: 1.4572 - val_acc: 0.4925\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.0114 - acc: 0.6570 - val_loss: 1.4516 - val_acc: 0.4962\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 0.9838 - acc: 0.6697 - val_loss: 1.4519 - val_acc: 0.4990\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 0.9657 - acc: 0.6776 - val_loss: 1.4483 - val_acc: 0.5016\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.9540 - acc: 0.6814 - val_loss: 1.4429 - val_acc: 0.4991\n",
      "Numbers of exp: 1, reduce_factor: 0.50, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s 222us/step - loss: 2.3364 - acc: 0.2393 - val_loss: 2.1873 - val_acc: 0.2926\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.8606 - acc: 0.3595 - val_loss: 1.9323 - val_acc: 0.3529\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.7235 - acc: 0.3988 - val_loss: 1.7887 - val_acc: 0.3885\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.6452 - acc: 0.4257 - val_loss: 1.7178 - val_acc: 0.4031\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.5899 - acc: 0.4473 - val_loss: 1.6655 - val_acc: 0.4200\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.5465 - acc: 0.4618 - val_loss: 1.6392 - val_acc: 0.4273\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5083 - acc: 0.4745 - val_loss: 1.6171 - val_acc: 0.4336\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.4757 - acc: 0.4857 - val_loss: 1.5900 - val_acc: 0.4394\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.4472 - acc: 0.4980 - val_loss: 1.5803 - val_acc: 0.4437\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.4222 - acc: 0.5053 - val_loss: 1.5619 - val_acc: 0.4504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.3977 - acc: 0.5139 - val_loss: 1.5489 - val_acc: 0.4554\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 1.3746 - acc: 0.5228 - val_loss: 1.5361 - val_acc: 0.4594\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.3541 - acc: 0.5309 - val_loss: 1.5285 - val_acc: 0.4586\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.3351 - acc: 0.5388 - val_loss: 1.5252 - val_acc: 0.4600\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.3163 - acc: 0.5442 - val_loss: 1.5127 - val_acc: 0.4660\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.2983 - acc: 0.5507 - val_loss: 1.5116 - val_acc: 0.4705\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 9s 185us/step - loss: 1.2807 - acc: 0.5579 - val_loss: 1.5057 - val_acc: 0.4703\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2638 - acc: 0.5640 - val_loss: 1.5001 - val_acc: 0.4729\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.2470 - acc: 0.5721 - val_loss: 1.5007 - val_acc: 0.4712\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.2318 - acc: 0.5754 - val_loss: 1.4893 - val_acc: 0.4767\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.2161 - acc: 0.5826 - val_loss: 1.4881 - val_acc: 0.4790\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.2016 - acc: 0.5874 - val_loss: 1.4897 - val_acc: 0.4745\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.1867 - acc: 0.5935 - val_loss: 1.4777 - val_acc: 0.4787\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.1720 - acc: 0.5994 - val_loss: 1.4740 - val_acc: 0.4793\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.1568 - acc: 0.6055 - val_loss: 1.4768 - val_acc: 0.4814\n",
      "Numbers of exp: 2, reduce_factor: 0.10, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 2.3580 - acc: 0.2358 - val_loss: 2.2434 - val_acc: 0.2785\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8745 - acc: 0.3524 - val_loss: 1.8928 - val_acc: 0.3547\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.7313 - acc: 0.3975 - val_loss: 1.7801 - val_acc: 0.3866\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.6540 - acc: 0.4210 - val_loss: 1.7190 - val_acc: 0.4037\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5982 - acc: 0.4421 - val_loss: 1.6773 - val_acc: 0.4165\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.5549 - acc: 0.4569 - val_loss: 1.6477 - val_acc: 0.4236\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5198 - acc: 0.4682 - val_loss: 1.6253 - val_acc: 0.4290\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.4871 - acc: 0.4801 - val_loss: 1.6006 - val_acc: 0.4409\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.4589 - acc: 0.4906 - val_loss: 1.5832 - val_acc: 0.4477\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.4331 - acc: 0.4999 - val_loss: 1.5790 - val_acc: 0.4466\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.4092 - acc: 0.5084 - val_loss: 1.5615 - val_acc: 0.4520\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.3865 - acc: 0.5193 - val_loss: 1.5480 - val_acc: 0.4606\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.3664 - acc: 0.5250 - val_loss: 1.5381 - val_acc: 0.4605\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.3451 - acc: 0.5327 - val_loss: 1.5280 - val_acc: 0.4601\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.3274 - acc: 0.5397 - val_loss: 1.5212 - val_acc: 0.4682\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.3092 - acc: 0.5472 - val_loss: 1.5111 - val_acc: 0.4730\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2916 - acc: 0.5536 - val_loss: 1.5098 - val_acc: 0.4710\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2744 - acc: 0.5596 - val_loss: 1.5040 - val_acc: 0.4770\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.2580 - acc: 0.5665 - val_loss: 1.5021 - val_acc: 0.4721\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2421 - acc: 0.5732 - val_loss: 1.4963 - val_acc: 0.4795\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.2264 - acc: 0.5780 - val_loss: 1.4924 - val_acc: 0.4782\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.2105 - acc: 0.5852 - val_loss: 1.4808 - val_acc: 0.4819\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.1953 - acc: 0.5898 - val_loss: 1.4789 - val_acc: 0.4826\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.1833 - acc: 0.5948 - val_loss: 1.4823 - val_acc: 0.4823\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.1673 - acc: 0.5999 - val_loss: 1.4729 - val_acc: 0.4862\n",
      "Numbers of exp: 3, reduce_factor: 0.10, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.3588 - acc: 0.2355 - val_loss: 2.2318 - val_acc: 0.2826\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8650 - acc: 0.3572 - val_loss: 1.9293 - val_acc: 0.3511\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.7229 - acc: 0.4017 - val_loss: 1.7885 - val_acc: 0.3893\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 1.6470 - acc: 0.4258 - val_loss: 1.7174 - val_acc: 0.4027\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.5937 - acc: 0.4431 - val_loss: 1.6739 - val_acc: 0.4151\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.5513 - acc: 0.4590 - val_loss: 1.6393 - val_acc: 0.4274\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.5148 - acc: 0.4710 - val_loss: 1.6270 - val_acc: 0.4296\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.4836 - acc: 0.4818 - val_loss: 1.6019 - val_acc: 0.4408\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.4558 - acc: 0.4913 - val_loss: 1.5821 - val_acc: 0.4505\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 10s 196us/step - loss: 1.4298 - acc: 0.5016 - val_loss: 1.5727 - val_acc: 0.4462\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.4078 - acc: 0.5079 - val_loss: 1.5616 - val_acc: 0.4552\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.3857 - acc: 0.5167 - val_loss: 1.5462 - val_acc: 0.4596\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.3650 - acc: 0.5231 - val_loss: 1.5343 - val_acc: 0.4625\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.3448 - acc: 0.5305 - val_loss: 1.5266 - val_acc: 0.4635\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.3260 - acc: 0.5373 - val_loss: 1.5262 - val_acc: 0.4654\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.3098 - acc: 0.5439 - val_loss: 1.5167 - val_acc: 0.4700\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2919 - acc: 0.5493 - val_loss: 1.5081 - val_acc: 0.4712\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.2746 - acc: 0.5565 - val_loss: 1.5046 - val_acc: 0.4735\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.2593 - acc: 0.5614 - val_loss: 1.4954 - val_acc: 0.4724\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.2441 - acc: 0.5670 - val_loss: 1.4936 - val_acc: 0.4810\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 1.2279 - acc: 0.5735 - val_loss: 1.4841 - val_acc: 0.4797\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.2148 - acc: 0.5789 - val_loss: 1.4841 - val_acc: 0.4786\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.1985 - acc: 0.5845 - val_loss: 1.4849 - val_acc: 0.4820\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.1865 - acc: 0.5888 - val_loss: 1.4757 - val_acc: 0.4874\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.1754 - acc: 0.5944 - val_loss: 1.4706 - val_acc: 0.4844\n",
      "Numbers of exp: 4, reduce_factor: 0.50, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.7797 - acc: 0.3831 - val_loss: 1.8453 - val_acc: 0.3753\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.5003 - acc: 0.4723 - val_loss: 2.0647 - val_acc: 0.3408\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.4003 - acc: 0.5080 - val_loss: 1.8930 - val_acc: 0.3527\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.3151 - acc: 0.5388 - val_loss: 1.8061 - val_acc: 0.3731\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.2512 - acc: 0.5584 - val_loss: 1.6979 - val_acc: 0.4139\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.1950 - acc: 0.5789 - val_loss: 2.2771 - val_acc: 0.3140\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.1447 - acc: 0.5969 - val_loss: 1.7102 - val_acc: 0.4155\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.1008 - acc: 0.6145 - val_loss: 1.9891 - val_acc: 0.3626\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.0505 - acc: 0.6321 - val_loss: 1.9458 - val_acc: 0.3753\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.0047 - acc: 0.6480 - val_loss: 1.7742 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.8996 - acc: 0.6883 - val_loss: 1.5983 - val_acc: 0.4525\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.8484 - acc: 0.7083 - val_loss: 1.5138 - val_acc: 0.4746\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.8116 - acc: 0.7232 - val_loss: 1.4317 - val_acc: 0.5034\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.7758 - acc: 0.7347 - val_loss: 1.5957 - val_acc: 0.4593\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 188us/step - loss: 0.7440 - acc: 0.7467 - val_loss: 1.5436 - val_acc: 0.4843\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 207us/step - loss: 0.7070 - acc: 0.7619 - val_loss: 1.5436 - val_acc: 0.4845\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 0.6815 - acc: 0.7705 - val_loss: 1.5937 - val_acc: 0.4838s - loss: 0.6\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 0.6508 - acc: 0.7807 - val_loss: 1.5916 - val_acc: 0.4810\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 9s 186us/step - loss: 0.5620 - acc: 0.8218 - val_loss: 1.5364 - val_acc: 0.4999\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 0.5221 - acc: 0.8364 - val_loss: 1.5477 - val_acc: 0.5116\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.4971 - acc: 0.8466 - val_loss: 1.5390 - val_acc: 0.5045\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 0.4769 - acc: 0.8552 - val_loss: 1.5800 - val_acc: 0.5090\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.4541 - acc: 0.8640 - val_loss: 1.5965 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.4049 - acc: 0.8870 - val_loss: 1.5458 - val_acc: 0.5234\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 0.3856 - acc: 0.8960 - val_loss: 1.5738 - val_acc: 0.5231\n",
      "Numbers of exp: 5, reduce_factor: 0.50, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.7657 - acc: 0.3884 - val_loss: 1.7016 - val_acc: 0.4039\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.4770 - acc: 0.4814 - val_loss: 1.6840 - val_acc: 0.4217\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.3828 - acc: 0.5175 - val_loss: 1.5337 - val_acc: 0.4618\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 1.3091 - acc: 0.5415 - val_loss: 1.5821 - val_acc: 0.4374\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.2538 - acc: 0.5608 - val_loss: 1.6483 - val_acc: 0.4230\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 11s 211us/step - loss: 1.1800 - acc: 0.5928 - val_loss: 1.4509 - val_acc: 0.4942\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.1452 - acc: 0.6053 - val_loss: 1.4060 - val_acc: 0.5017\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.1166 - acc: 0.6165 - val_loss: 1.4085 - val_acc: 0.5093\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.0901 - acc: 0.6241 - val_loss: 1.3940 - val_acc: 0.5078\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.0660 - acc: 0.6356 - val_loss: 1.3939 - val_acc: 0.5100\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.0420 - acc: 0.6462 - val_loss: 1.3909 - val_acc: 0.5099\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.0204 - acc: 0.6528 - val_loss: 1.3857 - val_acc: 0.5131\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 0.9966 - acc: 0.6629 - val_loss: 1.3919 - val_acc: 0.5095\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 10s 193us/step - loss: 0.9774 - acc: 0.6702 - val_loss: 1.4016 - val_acc: 0.5025\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 10s 197us/step - loss: 0.9437 - acc: 0.6872 - val_loss: 1.3626 - val_acc: 0.5243\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 0.9284 - acc: 0.6910 - val_loss: 1.3811 - val_acc: 0.5193\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 0.9185 - acc: 0.6956 - val_loss: 1.3673 - val_acc: 0.5215\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 0.9014 - acc: 0.7035 - val_loss: 1.3593 - val_acc: 0.5207\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.8950 - acc: 0.7065 - val_loss: 1.3570 - val_acc: 0.5224\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 0.8896 - acc: 0.7092 - val_loss: 1.3569 - val_acc: 0.5255\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.8839 - acc: 0.7106 - val_loss: 1.3621 - val_acc: 0.5246\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 0.8786 - acc: 0.7128 - val_loss: 1.3601 - val_acc: 0.5241\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 184us/step - loss: 0.8713 - acc: 0.7162 - val_loss: 1.3590 - val_acc: 0.5276\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 0.8681 - acc: 0.7178 - val_loss: 1.3574 - val_acc: 0.5271\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 0.8640 - acc: 0.7189 - val_loss: 1.3565 - val_acc: 0.5301\n",
      "Numbers of exp: 6, reduce_factor: 0.10, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 2.3668 - acc: 0.2321 - val_loss: 2.1630 - val_acc: 0.2774\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 2.0063 - acc: 0.3192 - val_loss: 2.0146 - val_acc: 0.3176\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.9016 - acc: 0.3505 - val_loss: 1.9337 - val_acc: 0.3409\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.8389 - acc: 0.3675 - val_loss: 1.8823 - val_acc: 0.3528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 183us/step - loss: 1.7950 - acc: 0.3817 - val_loss: 1.8525 - val_acc: 0.3658\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.7609 - acc: 0.3926 - val_loss: 1.8251 - val_acc: 0.3729\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.7328 - acc: 0.4007 - val_loss: 1.8034 - val_acc: 0.3788\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.7088 - acc: 0.4075 - val_loss: 1.7839 - val_acc: 0.3855\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.6880 - acc: 0.4149 - val_loss: 1.7685 - val_acc: 0.3908\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6692 - acc: 0.4216 - val_loss: 1.7542 - val_acc: 0.3936\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.6541 - acc: 0.4266 - val_loss: 1.7428 - val_acc: 0.3996\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.6376 - acc: 0.4328 - val_loss: 1.7328 - val_acc: 0.4005\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6243 - acc: 0.4377 - val_loss: 1.7237 - val_acc: 0.4019\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.6105 - acc: 0.4439 - val_loss: 1.7147 - val_acc: 0.4063\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.6001 - acc: 0.4451 - val_loss: 1.7057 - val_acc: 0.4077\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 10s 203us/step - loss: 1.5890 - acc: 0.4502 - val_loss: 1.6985 - val_acc: 0.4097\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 1.5777 - acc: 0.4542 - val_loss: 1.6928 - val_acc: 0.4122\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 11s 216us/step - loss: 1.5670 - acc: 0.4581 - val_loss: 1.6883 - val_acc: 0.4152\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 10s 202us/step - loss: 1.5581 - acc: 0.4612 - val_loss: 1.6794 - val_acc: 0.4144\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 10s 200us/step - loss: 1.5489 - acc: 0.4648 - val_loss: 1.6750 - val_acc: 0.4186\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.5399 - acc: 0.4677 - val_loss: 1.6691 - val_acc: 0.4203\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.5314 - acc: 0.4700 - val_loss: 1.6643 - val_acc: 0.4224\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5232 - acc: 0.4748 - val_loss: 1.6599 - val_acc: 0.4236\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.5151 - acc: 0.4768 - val_loss: 1.6562 - val_acc: 0.4290\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 10s 194us/step - loss: 1.5079 - acc: 0.4788 - val_loss: 1.6522 - val_acc: 0.4278\n",
      "Numbers of exp: 7, reduce_factor: 0.10, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 2.3790 - acc: 0.2330 - val_loss: 2.2152 - val_acc: 0.2759\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 11s 220us/step - loss: 2.0065 - acc: 0.3170 - val_loss: 2.0556 - val_acc: 0.3140\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 10s 206us/step - loss: 1.8984 - acc: 0.3481 - val_loss: 1.9566 - val_acc: 0.3347\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.8354 - acc: 0.3689 - val_loss: 1.9103 - val_acc: 0.3452\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.7904 - acc: 0.3820 - val_loss: 1.8753 - val_acc: 0.3553\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.7544 - acc: 0.3919 - val_loss: 1.8426 - val_acc: 0.3632\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.7267 - acc: 0.4036 - val_loss: 1.8157 - val_acc: 0.3720\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.7018 - acc: 0.4093 - val_loss: 1.7973 - val_acc: 0.3756\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.6818 - acc: 0.4164 - val_loss: 1.7802 - val_acc: 0.3810\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6637 - acc: 0.4238 - val_loss: 1.7656 - val_acc: 0.3854\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.6475 - acc: 0.4286 - val_loss: 1.7530 - val_acc: 0.3880\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.6326 - acc: 0.4326 - val_loss: 1.7436 - val_acc: 0.3911\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.6188 - acc: 0.4366 - val_loss: 1.7344 - val_acc: 0.3965\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.6054 - acc: 0.4416 - val_loss: 1.7258 - val_acc: 0.3977\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5939 - acc: 0.4456 - val_loss: 1.7168 - val_acc: 0.4006\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.5833 - acc: 0.4488 - val_loss: 1.7090 - val_acc: 0.4036\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.5727 - acc: 0.4514 - val_loss: 1.7029 - val_acc: 0.4068\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.5629 - acc: 0.4552 - val_loss: 1.6961 - val_acc: 0.4057\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5529 - acc: 0.4582 - val_loss: 1.6911 - val_acc: 0.4093\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.5444 - acc: 0.4613 - val_loss: 1.6859 - val_acc: 0.4129\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.5361 - acc: 0.4656 - val_loss: 1.6800 - val_acc: 0.4152\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.5287 - acc: 0.4670 - val_loss: 1.6766 - val_acc: 0.4157\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5203 - acc: 0.4698 - val_loss: 1.6711 - val_acc: 0.4171\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.5132 - acc: 0.4734 - val_loss: 1.6683 - val_acc: 0.4194\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.5049 - acc: 0.4763 - val_loss: 1.6632 - val_acc: 0.4194\n",
      "Numbers of exp: 8, reduce_factor: 0.50, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8061 - acc: 0.3727 - val_loss: 2.1172 - val_acc: 0.3135\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.5450 - acc: 0.4515 - val_loss: 2.2465 - val_acc: 0.2886\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.4406 - acc: 0.4909 - val_loss: 2.8880 - val_acc: 0.2202\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.3657 - acc: 0.5152 - val_loss: 3.1774 - val_acc: 0.2291\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.2996 - acc: 0.5409 - val_loss: 1.8053 - val_acc: 0.3705\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.2466 - acc: 0.5588 - val_loss: 1.9858 - val_acc: 0.3364\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.2080 - acc: 0.5739 - val_loss: 3.9785 - val_acc: 0.1826\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1615 - acc: 0.5914 - val_loss: 1.9018 - val_acc: 0.3728\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1239 - acc: 0.6025 - val_loss: 1.8346 - val_acc: 0.3832\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.0964 - acc: 0.6150 - val_loss: 2.1276 - val_acc: 0.3374\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9747 - acc: 0.6620 - val_loss: 1.5671 - val_acc: 0.4583\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9329 - acc: 0.6788 - val_loss: 1.4913 - val_acc: 0.4863\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.9008 - acc: 0.6882 - val_loss: 1.4144 - val_acc: 0.5075\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.8718 - acc: 0.6999 - val_loss: 1.4753 - val_acc: 0.4953\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.8414 - acc: 0.7105 - val_loss: 1.5380 - val_acc: 0.4803\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.8134 - acc: 0.7210 - val_loss: 1.5277 - val_acc: 0.4911\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.7851 - acc: 0.7295 - val_loss: 1.6730 - val_acc: 0.4636\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.7633 - acc: 0.7392 - val_loss: 1.6329 - val_acc: 0.4654\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 0.6831 - acc: 0.7731 - val_loss: 1.4480 - val_acc: 0.5158\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.6573 - acc: 0.7833 - val_loss: 1.4405 - val_acc: 0.5228\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.6390 - acc: 0.7899 - val_loss: 1.4498 - val_acc: 0.5233\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 0.6208 - acc: 0.7988 - val_loss: 1.4773 - val_acc: 0.5206\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.6014 - acc: 0.8057 - val_loss: 1.5167 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.5583 - acc: 0.8255 - val_loss: 1.4686 - val_acc: 0.5286\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 0.5458 - acc: 0.8294 - val_loss: 1.4795 - val_acc: 0.5278\n",
      "Numbers of exp: 9, reduce_factor: 0.50, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.8760 - acc: 0.3572 - val_loss: 1.9980 - val_acc: 0.3264\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.5780 - acc: 0.4483 - val_loss: 1.9096 - val_acc: 0.3460\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.4710 - acc: 0.4856 - val_loss: 1.7517 - val_acc: 0.3924\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3928 - acc: 0.5123 - val_loss: 1.7683 - val_acc: 0.4001\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.3365 - acc: 0.5344 - val_loss: 1.9955 - val_acc: 0.3580\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.2584 - acc: 0.5637 - val_loss: 1.5884 - val_acc: 0.4458\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.2212 - acc: 0.5772 - val_loss: 1.5704 - val_acc: 0.4522\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.1901 - acc: 0.5893 - val_loss: 1.5017 - val_acc: 0.4779\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.1603 - acc: 0.5994 - val_loss: 1.5003 - val_acc: 0.4733\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1326 - acc: 0.6107 - val_loss: 1.4634 - val_acc: 0.4864\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.1075 - acc: 0.6207 - val_loss: 1.4620 - val_acc: 0.4935\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.0814 - acc: 0.6308 - val_loss: 1.4663 - val_acc: 0.4869\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.0578 - acc: 0.6397 - val_loss: 1.5005 - val_acc: 0.4813\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.0125 - acc: 0.6620 - val_loss: 1.4355 - val_acc: 0.4969\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 10s 199us/step - loss: 0.9978 - acc: 0.6672 - val_loss: 1.4310 - val_acc: 0.4987\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 0.9831 - acc: 0.6727 - val_loss: 1.4062 - val_acc: 0.5108\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.9721 - acc: 0.6780 - val_loss: 1.4182 - val_acc: 0.5087\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.9575 - acc: 0.6830 - val_loss: 1.4236 - val_acc: 0.5073\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 0.9348 - acc: 0.6935 - val_loss: 1.4015 - val_acc: 0.5140\n",
      "Epoch 20/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 168us/step - loss: 0.9274 - acc: 0.6944 - val_loss: 1.4035 - val_acc: 0.5175\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 0.9204 - acc: 0.6993 - val_loss: 1.4079 - val_acc: 0.5076\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.9078 - acc: 0.7054 - val_loss: 1.4023 - val_acc: 0.5149\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9042 - acc: 0.7072 - val_loss: 1.4013 - val_acc: 0.5193\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 0.9007 - acc: 0.7078 - val_loss: 1.4040 - val_acc: 0.5142\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 0.8976 - acc: 0.7096 - val_loss: 1.4020 - val_acc: 0.5170\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Numbers of exp: 10, reduce_factor: 0.10, reduce_patient: 5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.6719 - acc: 0.1565 - val_loss: 2.5132 - val_acc: 0.1956\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 2.4359 - acc: 0.2101 - val_loss: 2.3725 - val_acc: 0.2326\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 2.2947 - acc: 0.2444 - val_loss: 2.2816 - val_acc: 0.2576\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 2.1965 - acc: 0.2703 - val_loss: 2.2104 - val_acc: 0.2738\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 2.1226 - acc: 0.2893 - val_loss: 2.1472 - val_acc: 0.2868\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 2.0628 - acc: 0.3075 - val_loss: 2.0971 - val_acc: 0.2987\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 2.0141 - acc: 0.3196 - val_loss: 2.0545 - val_acc: 0.3111\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.9719 - acc: 0.3315 - val_loss: 2.0178 - val_acc: 0.3215\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.9352 - acc: 0.3414 - val_loss: 1.9850 - val_acc: 0.3296\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.9018 - acc: 0.3502 - val_loss: 1.9563 - val_acc: 0.3357\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.8740 - acc: 0.3581 - val_loss: 1.9322 - val_acc: 0.3466\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.8482 - acc: 0.3657 - val_loss: 1.9080 - val_acc: 0.3516\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.8245 - acc: 0.3724 - val_loss: 1.8900 - val_acc: 0.3550\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.8033 - acc: 0.3771 - val_loss: 1.8682 - val_acc: 0.3658\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7845 - acc: 0.3843 - val_loss: 1.8507 - val_acc: 0.3704\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.7657 - acc: 0.3906 - val_loss: 1.8382 - val_acc: 0.3734\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.7484 - acc: 0.3952 - val_loss: 1.8255 - val_acc: 0.3767\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7320 - acc: 0.4003 - val_loss: 1.8107 - val_acc: 0.3802\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.7166 - acc: 0.4046 - val_loss: 1.8001 - val_acc: 0.3850\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7028 - acc: 0.4100 - val_loss: 1.7895 - val_acc: 0.3884\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6892 - acc: 0.4134 - val_loss: 1.7784 - val_acc: 0.3890\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.6764 - acc: 0.4180 - val_loss: 1.7698 - val_acc: 0.3907\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.6644 - acc: 0.4229 - val_loss: 1.7628 - val_acc: 0.3946\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6522 - acc: 0.4260 - val_loss: 1.7535 - val_acc: 0.3971\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.6417 - acc: 0.4301 - val_loss: 1.7436 - val_acc: 0.3995\n",
      "Numbers of exp: 11, reduce_factor: 0.10, reduce_patient: 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,742,474\n",
      "Trainable params: 1,740,682\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 2.6679 - acc: 0.1682 - val_loss: 2.5141 - val_acc: 0.1945\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 2.4142 - acc: 0.2163 - val_loss: 2.3606 - val_acc: 0.2278\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 2.2635 - acc: 0.2511 - val_loss: 2.2512 - val_acc: 0.2582\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 2.1606 - acc: 0.2773 - val_loss: 2.1681 - val_acc: 0.2758\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 2.0827 - acc: 0.2986 - val_loss: 2.0994 - val_acc: 0.2921\n",
      "Epoch 6/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 161us/step - loss: 2.0243 - acc: 0.3139 - val_loss: 2.0464 - val_acc: 0.3065\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.9764 - acc: 0.3278 - val_loss: 1.9985 - val_acc: 0.3209\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.9359 - acc: 0.3381 - val_loss: 1.9660 - val_acc: 0.3273\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.9018 - acc: 0.3487 - val_loss: 1.9358 - val_acc: 0.3364\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.8730 - acc: 0.3561 - val_loss: 1.9103 - val_acc: 0.3440\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.8465 - acc: 0.3641 - val_loss: 1.8878 - val_acc: 0.3514\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.8230 - acc: 0.3721 - val_loss: 1.8694 - val_acc: 0.3556\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.8011 - acc: 0.3778 - val_loss: 1.8513 - val_acc: 0.3610\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.7816 - acc: 0.3845 - val_loss: 1.8353 - val_acc: 0.3660\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.7631 - acc: 0.3895 - val_loss: 1.8204 - val_acc: 0.3681\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.7463 - acc: 0.3953 - val_loss: 1.8070 - val_acc: 0.3736\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.7305 - acc: 0.4003 - val_loss: 1.7939 - val_acc: 0.3773\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7147 - acc: 0.4045 - val_loss: 1.7828 - val_acc: 0.3799\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.7007 - acc: 0.4114 - val_loss: 1.7712 - val_acc: 0.3835\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6882 - acc: 0.4132 - val_loss: 1.7623 - val_acc: 0.3888\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6749 - acc: 0.4178 - val_loss: 1.7520 - val_acc: 0.3907\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.6624 - acc: 0.4222 - val_loss: 1.7438 - val_acc: 0.3930\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6513 - acc: 0.4263 - val_loss: 1.7352 - val_acc: 0.3945\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.6403 - acc: 0.4297 - val_loss: 1.7273 - val_acc: 0.4000\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6301 - acc: 0.4327 - val_loss: 1.7197 - val_acc: 0.4003\n"
     ]
    }
   ],
   "source": [
    "import itertools #enumerate(sequence, start=0)，返回一个枚举对象。sequence必须是序列或迭代器iterator，或者支持迭代的对象。enumerate()返回对象的每个元素都是一个元组，每个元组包括两个值，一个是计数，一个是sequence的值，计数是从start开始的，start默认为0。\n",
    "'''\n",
    "enumerate()是python的内置函数\n",
    "enumerate在字典上是枚举、列举的意思\n",
    "对于一个可迭代的（iterable）/可遍历的对象（如列表、字符串），enumerate将其组成一个索引序列，利用它可以同时获得索引和值\n",
    "enumerate多用于在for循环中得到计数\n",
    "例如对于一个seq，得到：\n",
    "enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中。\n",
    "　itertools.product(sequence，repeat) 　 #從sequence中拿出repeat個數做排列（repeat關鍵字傳參） 有放回的拿出  repeat與sequence的長度無關。\n",
    " itertools.product\n",
    " 上面的是获取相加的结果，下面的是获取相乘的结果\n",
    " a = itertools.product('浪子', '好帅')\n",
    "print(list(a))\n",
    "返回结果：\n",
    "\n",
    "[('浪', '好'), ('浪', '帅'), ('子', '好'), ('子', '帅')]\n",
    "'''\n",
    "results = {}\n",
    "         '''\n",
    "         optim, reduce_factor, reduce_patient 這三個變數在 itertools.product(optimizer_set, reduce_lr_factor, redice_lr_patie\n",
    "         '''\n",
    "    \n",
    "for i, (optim, reduce_factor, reduce_patient) in enumerate(itertools.product(optimizer_set, reduce_lr_factor, redice_lr_patient)):\n",
    "    print(\"Numbers of exp: %i, reduce_factor: %.2f, reduce_patient: %i\" % (i, reduce_factor, reduce_patient))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:]) ##多层感知机（MLP） #reshape（行，列）可以根据指定的数值将数据转换为特定的行数和列数，这个好理解，就是转换成矩阵。\n",
    "    model.summary() #summary() #模型摘要\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optim)\n",
    "    #compile() 函数将一个字符串编译为字节代码。\n",
    "    #亦称作多类的对数损失，注意使用该目标函数时，需要将标签转化为形如(nb_samples, nb_classes)的二值序列\n",
    "    #metrics 指標= accuracy\"準確性\n",
    "    #optimizer 優化器\n",
    "    \n",
    "    \"\"\"Code Here\n",
    "    設定 reduce learning rate 的 callback function\n",
    "    \"\"\"\n",
    "    #ReduceLROnPlateau 当指标变化小时，减少学习率\n",
    "    reduce_lr = ReduceLROnPlateau(factor=reduce_factor, #因子\n",
    "                              min_lr=1e-12, \n",
    "                              monitor='val_loss', \n",
    "                              patience=reduce_patient,  #patience: 当early stop被激活(如发现loss相比上一个epoch训练没有下降)，则经过patience个epoch后停止训练\n",
    "                              verbose=1)\n",
    "    \n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True,##shuffle：是否把數據隨機打亂之後再進行訓練\n",
    "              callbacks=[reduce_lr]\n",
    "             )\n",
    "\n",
    "    # Collect results\n",
    "    exp_name_tag = (\"exp-%s\" % (i))\n",
    "    results[exp_name_tag] = {'train-loss': model.history.history[\"loss\"],\n",
    "                             'valid-loss': model.history.history[\"val_loss\"],\n",
    "                             'train-acc': model.history.history[\"acc\"],\n",
    "                             'valid-acc': model.history.history[\"val_acc\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
