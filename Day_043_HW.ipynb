{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[作業重點]\n",
    "了解隨機森林改善了決策樹的什麼缺點？是用什麼方法改進的？\n",
    "\n",
    "作業\n",
    "閱讀以下兩篇文獻，了解隨機森林原理，並試著回答後續的思考問題\n",
    "\n",
    "隨機森林 (random forest) - 中文\n",
    "how random forest works - 英文\n",
    "隨機森林中的每一棵樹，是希望能夠\n",
    "\n",
    "沒有任何限制，讓樹可以持續生長 (讓樹生成很深，讓模型變得複雜)\n",
    "\n",
    "不要過度生長，避免 Overfitting\n",
    "\n",
    "答\n",
    "\n",
    "理論上隨機森林是不會過度配置的，然而實際上，操作隨機森林還是有可能遇到過度配置的問題，主要原因可能為樹的棵樹不夠無法反應大樹法則，或是抽樣時隨機性不夠，\n",
    "若變數之間相關性過高，會導致變數抽樣時可能會偏重某一些特徵，這樣樹種出來結果就不夠多樣性，過度配置就會產生。\n",
    "\n",
    "假設總共有 N 筆資料，每棵樹用取後放回的方式抽了總共 N 筆資料生成，請問這棵樹大約使用了多少 % 不重複的原資料生成? hint: 0.632 bootstrap\n",
    "答 (≈63.2%) \n",
    "\n",
    "\n",
    "Given a standard training set {\\displaystyle D} D of size n, bagging generates m \n",
    "new training sets {\\displaystyle D_{i}} D_{i}, each of size n′, by sampling from D uniformly and with \n",
    "replacement. By sampling with replacement, some observations may be repeated in each {\\displaystyle D_{i}} D_{i}. If n′=n, then for large n the set\n",
    "{\\displaystyle D_{i}} D_{i} is expected to have the fraction (1 - 1/e) (≈63.2%) \n",
    "of the unique examples of D, the rest being duplicates.[1] This kind of sample is known as a bootstrap sample. Then, m models are fitted using the above m bootstrap samples and combined by averaging the output (for regression) or voting (for classification).\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
