{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 模型的泛化能力 (generalization) 是指什麼？\n",
    "答:過擬合  欠擬合\n",
    "2.分類問題與回歸問題分別可用的目標函數有哪些？\n",
    "答\n",
    "1.迴歸問題[1]\n",
    "迴歸問題中有衆多損失函數，而目前機器學習主流的損失函數還是均方誤差函數，平均絕對誤差也使用較多，在此基礎上發展出了很多其他函數，Huber損失函數就是其中一種。\n",
    "\n",
    "1.1平均絕對誤差——L1損失函數\n",
    "平均絕對誤差（MAE）是另一種常用的迴歸損失函數，它是目標值與預測值之差絕對值的和，表示了預測值的平均誤差幅度，而不需要考慮誤差的方向，範圍是0到∞\n",
    "1.2均方誤差——L2損失函數\n",
    "\n",
    "1.3 Huber損失——平滑平均絕對誤差\n",
    "\n",
    "2.分類問題\n",
    "分類問題相對迴歸問題更爲具體，目標量只存在於一個有限集合，並且是離散的。分類問題往往比迴歸問題多出了一步，用於判斷類別。迴歸問題的損失函數就是性能度量函數，而分類問題的損失函數不能直接用於性能度量，其最終評估的標準不是離目標的距離，而是類別判斷的準確率。爲了最大地提升類別判斷準確率，我們需要爲分類問題定義不同的損失函數。\n",
    "\n",
    "2.1  0-1損失函數\n",
    "\n",
    "2.2 交叉熵損失函數（Logistic迴歸）[6]\n",
    "\n",
    "2.3 交叉熵損失函數（Softmax激活）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
