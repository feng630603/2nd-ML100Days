{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Work\n",
    "請結合前面的知識與程式碼，比較不同的 regularization 的組合對訓練的結果與影響：如 dropout, regularizers, batch-normalization 等\n",
    "'''\n",
    "import os\n",
    "import keras\n",
    "import itertools\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    return model\n",
    "'''\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\"\"\"\n",
    "建立神經網路，並加入 BN layer\n",
    "\"\"\"\n",
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128],drp_ratio=0.3, BATCH_SIZE=1024,l2_ratio=1e-5):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "           \n",
    "            x = Dropout(drp_ratio)(x)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, \n",
    "                                   activation=\"relu\", \n",
    "                                   name=\"hidden_layer\"+str(i+1))(x)\n",
    "            \n",
    "            x = Dropout(drp_ratio)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE_EXP = [2, 16, 32, 128, 256]\n",
    "MOMENTUM = 0.95\n",
    "Dropout_EXP = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with BATCH_SIZE = 2.000000\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,739,402\n",
      "Trainable params: 1,739,146\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 2.3325 - acc: 0.1106 - val_loss: 2.2888 - val_acc: 0.1497\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2998 - acc: 0.1155 - val_loss: 2.2738 - val_acc: 0.1452\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2986 - acc: 0.1145 - val_loss: 2.2718 - val_acc: 0.1248\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2970 - acc: 0.1179 - val_loss: 2.2706 - val_acc: 0.1324\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2961 - acc: 0.1166 - val_loss: 2.2769 - val_acc: 0.1376\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2954 - acc: 0.1181 - val_loss: 2.2656 - val_acc: 0.1367\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2942 - acc: 0.1191 - val_loss: 2.2620 - val_acc: 0.1557\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2946 - acc: 0.1179 - val_loss: 2.2796 - val_acc: 0.1382\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2979 - acc: 0.1151 - val_loss: 2.2766 - val_acc: 0.1178\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2975 - acc: 0.1155 - val_loss: 2.2735 - val_acc: 0.1341\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2972 - acc: 0.1135 - val_loss: 2.2871 - val_acc: 0.1141\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 2.2967 - acc: 0.1166 - val_loss: 2.2787 - val_acc: 0.1179\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 2.2971 - acc: 0.1162 - val_loss: 2.2734 - val_acc: 0.1546\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 2.2984 - acc: 0.1122 - val_loss: 2.2841 - val_acc: 0.1217\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 2.2986 - acc: 0.1135 - val_loss: 2.2892 - val_acc: 0.1082\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 2.2975 - acc: 0.1151 - val_loss: 2.2843 - val_acc: 0.1210\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 2.2969 - acc: 0.1177 - val_loss: 2.2765 - val_acc: 0.1329\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 2.2969 - acc: 0.1170 - val_loss: 2.2826 - val_acc: 0.1252\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 284s 6ms/step - loss: 2.2979 - acc: 0.1128 - val_loss: 2.2838 - val_acc: 0.1244\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2986 - acc: 0.1157 - val_loss: 2.2781 - val_acc: 0.1458\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2981 - acc: 0.1159 - val_loss: 2.2779 - val_acc: 0.1257\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2988 - acc: 0.1157 - val_loss: 2.2787 - val_acc: 0.1378\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2982 - acc: 0.1165 - val_loss: 2.2796 - val_acc: 0.1134\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 279s 6ms/step - loss: 2.2981 - acc: 0.1151 - val_loss: 2.2758 - val_acc: 0.1404\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2983 - acc: 0.1147 - val_loss: 2.2736 - val_acc: 0.1445\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2993 - acc: 0.1114 - val_loss: 2.2735 - val_acc: 0.1410\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.2994 - acc: 0.1123 - val_loss: 2.2835 - val_acc: 0.1076\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 280s 6ms/step - loss: 2.3003 - acc: 0.1133 - val_loss: 2.2842 - val_acc: 0.1154\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.3004 - acc: 0.1142 - val_loss: 2.2813 - val_acc: 0.1302\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2988 - acc: 0.1141 - val_loss: 2.2767 - val_acc: 0.1461\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2983 - acc: 0.1150 - val_loss: 2.2870 - val_acc: 0.1162\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2988 - acc: 0.1159 - val_loss: 2.2731 - val_acc: 0.1472\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2972 - acc: 0.1172 - val_loss: 2.2744 - val_acc: 0.1474\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2990 - acc: 0.1133 - val_loss: 2.2763 - val_acc: 0.1301\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2980 - acc: 0.1182 - val_loss: 2.2763 - val_acc: 0.1371\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2987 - acc: 0.1145 - val_loss: 2.2802 - val_acc: 0.1260\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 2.2987 - acc: 0.1167 - val_loss: 2.2776 - val_acc: 0.1493\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2987 - acc: 0.1134 - val_loss: 2.2709 - val_acc: 0.1447\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2987 - acc: 0.1144 - val_loss: 2.2770 - val_acc: 0.1345\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2990 - acc: 0.1137 - val_loss: 2.2761 - val_acc: 0.1503\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2979 - acc: 0.1162 - val_loss: 2.2850 - val_acc: 0.1079\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 2.2981 - acc: 0.1145 - val_loss: 2.2763 - val_acc: 0.1459\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 2.2979 - acc: 0.1172 - val_loss: 2.2772 - val_acc: 0.1440\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 281s 6ms/step - loss: 2.2984 - acc: 0.1157 - val_loss: 2.2784 - val_acc: 0.1223\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2980 - acc: 0.1146 - val_loss: 2.2809 - val_acc: 0.1157\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2967 - acc: 0.1170 - val_loss: 2.2743 - val_acc: 0.1385\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2995 - acc: 0.1144 - val_loss: 2.2856 - val_acc: 0.1142\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2999 - acc: 0.1156 - val_loss: 2.2771 - val_acc: 0.1429\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 283s 6ms/step - loss: 2.2996 - acc: 0.1140 - val_loss: 2.2798 - val_acc: 0.1342\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 282s 6ms/step - loss: 2.2990 - acc: 0.1140 - val_loss: 2.2802 - val_acc: 0.1500\n",
      "Experiment with BATCH_SIZE = 16.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,739,402\n",
      "Trainable params: 1,739,146\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 2.1153 - acc: 0.2273 - val_loss: 1.8613 - val_acc: 0.3200\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.9119 - acc: 0.3024 - val_loss: 1.7892 - val_acc: 0.3467\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.8510 - acc: 0.3324 - val_loss: 1.7371 - val_acc: 0.3755\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 1.8005 - acc: 0.3490 - val_loss: 1.6871 - val_acc: 0.4087\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.7613 - acc: 0.3663 - val_loss: 1.6507 - val_acc: 0.4076\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.7345 - acc: 0.3765 - val_loss: 1.6145 - val_acc: 0.4253\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.7062 - acc: 0.3893 - val_loss: 1.6151 - val_acc: 0.4216\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.6905 - acc: 0.3976 - val_loss: 1.5751 - val_acc: 0.4428\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.6697 - acc: 0.4038 - val_loss: 1.5566 - val_acc: 0.4515\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.6447 - acc: 0.4158 - val_loss: 1.5641 - val_acc: 0.4423\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.6320 - acc: 0.4207 - val_loss: 1.5553 - val_acc: 0.4483\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 1.6167 - acc: 0.4257 - val_loss: 1.5130 - val_acc: 0.4625\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.6055 - acc: 0.4287 - val_loss: 1.4854 - val_acc: 0.4776\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.5973 - acc: 0.4335 - val_loss: 1.5131 - val_acc: 0.4598\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.5813 - acc: 0.4379 - val_loss: 1.5183 - val_acc: 0.4562\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5672 - acc: 0.4452 - val_loss: 1.4736 - val_acc: 0.4800\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 1.5577 - acc: 0.4476 - val_loss: 1.4869 - val_acc: 0.4746\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5509 - acc: 0.4494 - val_loss: 1.4570 - val_acc: 0.4908\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 1.5358 - acc: 0.4537 - val_loss: 1.4990 - val_acc: 0.4666\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 1.5301 - acc: 0.4574 - val_loss: 1.4586 - val_acc: 0.4775\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 1.5225 - acc: 0.4608 - val_loss: 1.4752 - val_acc: 0.4685\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 1.5170 - acc: 0.4625 - val_loss: 1.4278 - val_acc: 0.4983\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.4988 - acc: 0.4705 - val_loss: 1.4396 - val_acc: 0.4930\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 64s 1ms/step - loss: 1.4899 - acc: 0.4703 - val_loss: 1.4343 - val_acc: 0.4927\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.4799 - acc: 0.4758 - val_loss: 1.4127 - val_acc: 0.5024\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.4781 - acc: 0.4768 - val_loss: 1.4201 - val_acc: 0.4973\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 65s 1ms/step - loss: 1.4709 - acc: 0.4814 - val_loss: 1.3984 - val_acc: 0.5076\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.4597 - acc: 0.4849 - val_loss: 1.3971 - val_acc: 0.5045\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 67s 1ms/step - loss: 1.4518 - acc: 0.4889 - val_loss: 1.4110 - val_acc: 0.4982\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 66s 1ms/step - loss: 1.4434 - acc: 0.4910 - val_loss: 1.3912 - val_acc: 0.5068\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.4337 - acc: 0.4941 - val_loss: 1.3863 - val_acc: 0.5070\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4325 - acc: 0.4948 - val_loss: 1.3851 - val_acc: 0.5089\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 1.4258 - acc: 0.4997 - val_loss: 1.3845 - val_acc: 0.5116\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.4202 - acc: 0.4986 - val_loss: 1.3654 - val_acc: 0.5137\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.4139 - acc: 0.4995 - val_loss: 1.3830 - val_acc: 0.5163\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.4103 - acc: 0.5048 - val_loss: 1.3781 - val_acc: 0.5082\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 1.4060 - acc: 0.5042 - val_loss: 1.4287 - val_acc: 0.4896\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 71s 1ms/step - loss: 1.3988 - acc: 0.5088 - val_loss: 1.3685 - val_acc: 0.5146\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 1.3919 - acc: 0.5093 - val_loss: 1.3592 - val_acc: 0.5205\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 72s 1ms/step - loss: 1.3892 - acc: 0.5141 - val_loss: 1.3691 - val_acc: 0.5157\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.3854 - acc: 0.5135 - val_loss: 1.3697 - val_acc: 0.5085\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 47s 938us/step - loss: 1.3770 - acc: 0.5155 - val_loss: 1.3755 - val_acc: 0.5111\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 47s 940us/step - loss: 1.3698 - acc: 0.5185 - val_loss: 1.3600 - val_acc: 0.5156\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 47s 946us/step - loss: 1.3641 - acc: 0.5184 - val_loss: 1.3590 - val_acc: 0.5224\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 48s 953us/step - loss: 1.3596 - acc: 0.5221 - val_loss: 1.3607 - val_acc: 0.5212\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 48s 951us/step - loss: 1.3525 - acc: 0.5256 - val_loss: 1.3478 - val_acc: 0.5168\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 48s 966us/step - loss: 1.3485 - acc: 0.5271 - val_loss: 1.3425 - val_acc: 0.5205\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 48s 966us/step - loss: 1.3467 - acc: 0.5265 - val_loss: 1.3350 - val_acc: 0.5288\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.3438 - acc: 0.5263 - val_loss: 1.3309 - val_acc: 0.5236\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 49s 974us/step - loss: 1.3354 - acc: 0.5308 - val_loss: 1.3436 - val_acc: 0.5272\n",
      "Experiment with BATCH_SIZE = 32.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,739,402\n",
      "Trainable params: 1,739,146\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 32s 639us/step - loss: 2.1214 - acc: 0.2317 - val_loss: 1.8545 - val_acc: 0.3304\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 31s 613us/step - loss: 1.8781 - acc: 0.3154 - val_loss: 1.7744 - val_acc: 0.3530\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 31s 620us/step - loss: 1.8179 - acc: 0.3404 - val_loss: 1.6854 - val_acc: 0.3942\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 31s 620us/step - loss: 1.7715 - acc: 0.3607 - val_loss: 1.6714 - val_acc: 0.3833\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 31s 626us/step - loss: 1.7336 - acc: 0.3769 - val_loss: 1.6031 - val_acc: 0.4308\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 31s 622us/step - loss: 1.7027 - acc: 0.3893 - val_loss: 1.5912 - val_acc: 0.4323\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 32s 632us/step - loss: 1.6780 - acc: 0.3971 - val_loss: 1.5634 - val_acc: 0.4478\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 31s 630us/step - loss: 1.6479 - acc: 0.4077 - val_loss: 1.5467 - val_acc: 0.4476\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 32s 632us/step - loss: 1.6332 - acc: 0.4160 - val_loss: 1.5355 - val_acc: 0.4546\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 32s 644us/step - loss: 1.6107 - acc: 0.4265 - val_loss: 1.5293 - val_acc: 0.4531\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 32s 648us/step - loss: 1.5938 - acc: 0.4274 - val_loss: 1.5146 - val_acc: 0.4565\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 32s 648us/step - loss: 1.5792 - acc: 0.4354 - val_loss: 1.5023 - val_acc: 0.4621\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 32s 640us/step - loss: 1.5560 - acc: 0.4439 - val_loss: 1.4709 - val_acc: 0.4696\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 33s 655us/step - loss: 1.5481 - acc: 0.4454 - val_loss: 1.4549 - val_acc: 0.4748\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 32s 644us/step - loss: 1.5292 - acc: 0.4536 - val_loss: 1.4576 - val_acc: 0.4838\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 1.5283 - acc: 0.4524 - val_loss: 1.4525 - val_acc: 0.4790\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 33s 652us/step - loss: 1.5134 - acc: 0.4585 - val_loss: 1.4333 - val_acc: 0.4866\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 33s 659us/step - loss: 1.5032 - acc: 0.4664 - val_loss: 1.4423 - val_acc: 0.4773\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 34s 674us/step - loss: 1.4832 - acc: 0.4721 - val_loss: 1.4014 - val_acc: 0.4929\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 1.4791 - acc: 0.4716 - val_loss: 1.4068 - val_acc: 0.4926\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 1.4677 - acc: 0.4757 - val_loss: 1.4370 - val_acc: 0.4837\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 1.4629 - acc: 0.4783 - val_loss: 1.3957 - val_acc: 0.5001\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 34s 676us/step - loss: 1.4514 - acc: 0.4812 - val_loss: 1.3897 - val_acc: 0.5051\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 34s 684us/step - loss: 1.4422 - acc: 0.4880 - val_loss: 1.3784 - val_acc: 0.5016\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 1.4284 - acc: 0.4911 - val_loss: 1.3717 - val_acc: 0.5069\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 33s 666us/step - loss: 1.4174 - acc: 0.4936 - val_loss: 1.3746 - val_acc: 0.5095\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 33s 666us/step - loss: 1.4153 - acc: 0.4972 - val_loss: 1.4032 - val_acc: 0.4986\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 33s 669us/step - loss: 1.4140 - acc: 0.4961 - val_loss: 1.3947 - val_acc: 0.4946\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 33s 670us/step - loss: 1.3984 - acc: 0.5045 - val_loss: 1.3662 - val_acc: 0.5104\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.3920 - acc: 0.5078 - val_loss: 1.3767 - val_acc: 0.5080\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.3936 - acc: 0.5049 - val_loss: 1.3770 - val_acc: 0.5013\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 34s 682us/step - loss: 1.3825 - acc: 0.5090 - val_loss: 1.3545 - val_acc: 0.5112\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 33s 663us/step - loss: 1.3732 - acc: 0.5106 - val_loss: 1.3586 - val_acc: 0.5144\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 35s 696us/step - loss: 1.3720 - acc: 0.5115 - val_loss: 1.3287 - val_acc: 0.5230\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 34s 689us/step - loss: 1.3643 - acc: 0.5169 - val_loss: 1.3274 - val_acc: 0.5234\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 35s 703us/step - loss: 1.3572 - acc: 0.5184 - val_loss: 1.3307 - val_acc: 0.5169\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 36s 711us/step - loss: 1.3556 - acc: 0.5174 - val_loss: 1.3293 - val_acc: 0.5267\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 28s 557us/step - loss: 1.3464 - acc: 0.5218 - val_loss: 1.3282 - val_acc: 0.5248\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 28s 559us/step - loss: 1.3358 - acc: 0.5253 - val_loss: 1.3611 - val_acc: 0.5192\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 28s 562us/step - loss: 1.3313 - acc: 0.5257 - val_loss: 1.3255 - val_acc: 0.5237\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 28s 558us/step - loss: 1.3286 - acc: 0.5249 - val_loss: 1.3189 - val_acc: 0.5287\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 28s 562us/step - loss: 1.3203 - acc: 0.5318 - val_loss: 1.3127 - val_acc: 0.5231\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 28s 564us/step - loss: 1.3183 - acc: 0.5303 - val_loss: 1.3170 - val_acc: 0.5261\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 28s 566us/step - loss: 1.3121 - acc: 0.5340 - val_loss: 1.3080 - val_acc: 0.5305\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 28s 568us/step - loss: 1.3085 - acc: 0.5361 - val_loss: 1.3075 - val_acc: 0.5319\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 28s 568us/step - loss: 1.2971 - acc: 0.5413 - val_loss: 1.3015 - val_acc: 0.5328\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 29s 571us/step - loss: 1.2980 - acc: 0.5388 - val_loss: 1.3216 - val_acc: 0.5288\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 29s 573us/step - loss: 1.2938 - acc: 0.5427 - val_loss: 1.3846 - val_acc: 0.5011\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 29s 578us/step - loss: 1.2838 - acc: 0.5448 - val_loss: 1.2923 - val_acc: 0.5351\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 29s 577us/step - loss: 1.2764 - acc: 0.5477 - val_loss: 1.2910 - val_acc: 0.5328\n",
      "Experiment with BATCH_SIZE = 128.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,739,402\n",
      "Trainable params: 1,739,146\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 16s 312us/step - loss: 2.2649 - acc: 0.2136 - val_loss: 1.8835 - val_acc: 0.3280\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.9168 - acc: 0.3071 - val_loss: 1.7694 - val_acc: 0.3674\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.8201 - acc: 0.3416 - val_loss: 1.6818 - val_acc: 0.3902\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 15s 298us/step - loss: 1.7661 - acc: 0.3644 - val_loss: 1.6443 - val_acc: 0.4130\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 15s 296us/step - loss: 1.7266 - acc: 0.3803 - val_loss: 1.5955 - val_acc: 0.4261\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.6938 - acc: 0.3915 - val_loss: 1.5924 - val_acc: 0.4244\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 1.6718 - acc: 0.4015 - val_loss: 1.5490 - val_acc: 0.4413\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 1.6456 - acc: 0.4086 - val_loss: 1.5329 - val_acc: 0.4513\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 15s 296us/step - loss: 1.6258 - acc: 0.4169 - val_loss: 1.5221 - val_acc: 0.4577\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.6058 - acc: 0.4223 - val_loss: 1.4990 - val_acc: 0.4554\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 15s 302us/step - loss: 1.5942 - acc: 0.4281 - val_loss: 1.4827 - val_acc: 0.4665\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 1.5692 - acc: 0.4384 - val_loss: 1.4962 - val_acc: 0.4636\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 15s 299us/step - loss: 1.5592 - acc: 0.4414 - val_loss: 1.4587 - val_acc: 0.4768\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 15s 301us/step - loss: 1.5404 - acc: 0.4460 - val_loss: 1.4514 - val_acc: 0.4764\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 15s 300us/step - loss: 1.5310 - acc: 0.4522 - val_loss: 1.4555 - val_acc: 0.4789\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.5207 - acc: 0.4560 - val_loss: 1.4421 - val_acc: 0.4801\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 15s 298us/step - loss: 1.5134 - acc: 0.4562 - val_loss: 1.4561 - val_acc: 0.4738\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 15s 301us/step - loss: 1.4958 - acc: 0.4630 - val_loss: 1.4398 - val_acc: 0.4826\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.4871 - acc: 0.4685 - val_loss: 1.4069 - val_acc: 0.4932\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 15s 302us/step - loss: 1.4764 - acc: 0.4679 - val_loss: 1.4178 - val_acc: 0.4884\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 1.4744 - acc: 0.4716 - val_loss: 1.4076 - val_acc: 0.4953\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 15s 304us/step - loss: 1.4616 - acc: 0.4758 - val_loss: 1.4171 - val_acc: 0.4937\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 1.4517 - acc: 0.4773 - val_loss: 1.4043 - val_acc: 0.5003\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 15s 307us/step - loss: 1.4448 - acc: 0.4818 - val_loss: 1.4169 - val_acc: 0.4935\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.4343 - acc: 0.4859 - val_loss: 1.4010 - val_acc: 0.4942\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 16s 310us/step - loss: 1.4249 - acc: 0.4888 - val_loss: 1.3865 - val_acc: 0.5030\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.4215 - acc: 0.4890 - val_loss: 1.3783 - val_acc: 0.5015\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.4117 - acc: 0.4941 - val_loss: 1.3712 - val_acc: 0.5063\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 16s 311us/step - loss: 1.4100 - acc: 0.4920 - val_loss: 1.3789 - val_acc: 0.5050\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 16s 314us/step - loss: 1.4011 - acc: 0.4974 - val_loss: 1.3730 - val_acc: 0.5092\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.3878 - acc: 0.5005 - val_loss: 1.3719 - val_acc: 0.5044\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.3815 - acc: 0.5030 - val_loss: 1.3964 - val_acc: 0.4974\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 16s 318us/step - loss: 1.3793 - acc: 0.5057 - val_loss: 1.3611 - val_acc: 0.5118\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 16s 317us/step - loss: 1.3764 - acc: 0.5052 - val_loss: 1.3716 - val_acc: 0.5093\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 14s 283us/step - loss: 1.3622 - acc: 0.5100 - val_loss: 1.3423 - val_acc: 0.5190\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.3604 - acc: 0.5102 - val_loss: 1.3426 - val_acc: 0.5215\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.3500 - acc: 0.5162 - val_loss: 1.3467 - val_acc: 0.5182\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 14s 283us/step - loss: 1.3466 - acc: 0.5182 - val_loss: 1.3518 - val_acc: 0.5152\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.3403 - acc: 0.5231 - val_loss: 1.3398 - val_acc: 0.5166\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.3344 - acc: 0.5214 - val_loss: 1.3373 - val_acc: 0.5230\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.3292 - acc: 0.5203 - val_loss: 1.3505 - val_acc: 0.5182\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3240 - acc: 0.5235 - val_loss: 1.3417 - val_acc: 0.5173\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.3229 - acc: 0.5231 - val_loss: 1.3292 - val_acc: 0.5239\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.3071 - acc: 0.5305 - val_loss: 1.3302 - val_acc: 0.5235\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 1.3059 - acc: 0.5313 - val_loss: 1.3268 - val_acc: 0.5253\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3002 - acc: 0.5354 - val_loss: 1.3261 - val_acc: 0.5267\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3006 - acc: 0.5342 - val_loss: 1.3202 - val_acc: 0.5305\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.2946 - acc: 0.5365 - val_loss: 1.3343 - val_acc: 0.5290\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 14s 289us/step - loss: 1.2894 - acc: 0.5400 - val_loss: 1.3171 - val_acc: 0.5257\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 14s 289us/step - loss: 1.2896 - acc: 0.5383 - val_loss: 1.3388 - val_acc: 0.5207\n",
      "Experiment with BATCH_SIZE = 256.000000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,739,402\n",
      "Trainable params: 1,739,146\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 2.4006 - acc: 0.1852 - val_loss: 1.9459 - val_acc: 0.2898\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 2.0148 - acc: 0.2782 - val_loss: 1.8358 - val_acc: 0.3348\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 1.9025 - acc: 0.3149 - val_loss: 1.7463 - val_acc: 0.3804\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 12s 246us/step - loss: 1.8316 - acc: 0.3385 - val_loss: 1.6898 - val_acc: 0.3997\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 12s 239us/step - loss: 1.7821 - acc: 0.3552 - val_loss: 1.6619 - val_acc: 0.4061\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.7467 - acc: 0.3700 - val_loss: 1.6091 - val_acc: 0.4302\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.7133 - acc: 0.3836 - val_loss: 1.6024 - val_acc: 0.4317\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.6873 - acc: 0.3945 - val_loss: 1.5641 - val_acc: 0.4435\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.6583 - acc: 0.4057 - val_loss: 1.5695 - val_acc: 0.4360\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 1.6439 - acc: 0.4086 - val_loss: 1.5416 - val_acc: 0.4476\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.6256 - acc: 0.4155 - val_loss: 1.5536 - val_acc: 0.4487\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.6096 - acc: 0.4220 - val_loss: 1.5159 - val_acc: 0.4483\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 12s 240us/step - loss: 1.5877 - acc: 0.4283 - val_loss: 1.4906 - val_acc: 0.4666\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.5770 - acc: 0.4336 - val_loss: 1.4897 - val_acc: 0.4685\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.5644 - acc: 0.4370 - val_loss: 1.4743 - val_acc: 0.4700\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 12s 243us/step - loss: 1.5624 - acc: 0.4404 - val_loss: 1.4798 - val_acc: 0.4707\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 12s 247us/step - loss: 1.5389 - acc: 0.4482 - val_loss: 1.4599 - val_acc: 0.4791\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 1.5246 - acc: 0.4538 - val_loss: 1.4538 - val_acc: 0.4761\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 12s 244us/step - loss: 1.5131 - acc: 0.4559 - val_loss: 1.4346 - val_acc: 0.4786\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.5021 - acc: 0.4613 - val_loss: 1.4509 - val_acc: 0.4742\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.4865 - acc: 0.4659 - val_loss: 1.4298 - val_acc: 0.4815\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.4770 - acc: 0.4703 - val_loss: 1.4233 - val_acc: 0.4882\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.4748 - acc: 0.4700 - val_loss: 1.4110 - val_acc: 0.4899\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.4679 - acc: 0.4725 - val_loss: 1.4083 - val_acc: 0.4935\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.4531 - acc: 0.4805 - val_loss: 1.4099 - val_acc: 0.4943\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.4536 - acc: 0.4780 - val_loss: 1.3961 - val_acc: 0.4990\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.4491 - acc: 0.4788 - val_loss: 1.3953 - val_acc: 0.5009\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.4303 - acc: 0.4854 - val_loss: 1.3887 - val_acc: 0.4970\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.4213 - acc: 0.4917 - val_loss: 1.3861 - val_acc: 0.5019\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.4219 - acc: 0.4880 - val_loss: 1.3950 - val_acc: 0.4936\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.4203 - acc: 0.4884 - val_loss: 1.4030 - val_acc: 0.4926\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.4054 - acc: 0.4961 - val_loss: 1.4209 - val_acc: 0.4894\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.4038 - acc: 0.4952 - val_loss: 1.3812 - val_acc: 0.5086\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.3947 - acc: 0.4965 - val_loss: 1.3684 - val_acc: 0.5075\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 1.3877 - acc: 0.4999 - val_loss: 1.3891 - val_acc: 0.4978\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 12s 233us/step - loss: 1.3825 - acc: 0.5003 - val_loss: 1.3725 - val_acc: 0.5021\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 1.3776 - acc: 0.5033 - val_loss: 1.3720 - val_acc: 0.5029\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 11s 227us/step - loss: 1.3711 - acc: 0.5097 - val_loss: 1.3648 - val_acc: 0.5075\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.3614 - acc: 0.5108 - val_loss: 1.3612 - val_acc: 0.5099\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.3582 - acc: 0.5114 - val_loss: 1.3566 - val_acc: 0.5183\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 11s 230us/step - loss: 1.3532 - acc: 0.5142 - val_loss: 1.3571 - val_acc: 0.5091\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.3415 - acc: 0.5161 - val_loss: 1.3464 - val_acc: 0.5145\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 12s 231us/step - loss: 1.3312 - acc: 0.5205 - val_loss: 1.3517 - val_acc: 0.5120\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 11s 228us/step - loss: 1.3333 - acc: 0.5222 - val_loss: 1.3535 - val_acc: 0.5144\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 1.3240 - acc: 0.5250 - val_loss: 1.3498 - val_acc: 0.5134\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 11s 229us/step - loss: 1.3192 - acc: 0.5271 - val_loss: 1.3646 - val_acc: 0.5107\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 12s 230us/step - loss: 1.3110 - acc: 0.5318 - val_loss: 1.3430 - val_acc: 0.5193\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 12s 232us/step - loss: 1.3041 - acc: 0.5295 - val_loss: 1.3230 - val_acc: 0.5248\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.2959 - acc: 0.5358 - val_loss: 1.3533 - val_acc: 0.5176\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.2995 - acc: 0.5357 - val_loss: 1.3347 - val_acc: 0.5216\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "使用迴圈建立不同的帶不同  Batch_size 的模型並訓練\n",
    "\"\"\"\n",
    "for BATCH_SIZE in BATCH_SIZE_EXP:\n",
    "    keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "    print(\"Experiment with BATCH_SIZE = %f\" % (BATCH_SIZE))\n",
    "    model = build_mlp(input_shape=x_train.shape[1:],drp_ratio=Dropout_EXP)\n",
    "    model.summary()\n",
    "    optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, nesterov=True, momentum=MOMENTUM)\n",
    "    model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "    model.fit(x_train, y_train, \n",
    "              epochs=EPOCHS, \n",
    "              batch_size=BATCH_SIZE, \n",
    "              validation_data=(x_test, y_test), \n",
    "              shuffle=True)\n",
    "    \n",
    "    # Collect results\n",
    "    train_loss = model.history.history[\"loss\"]\n",
    "    valid_loss = model.history.history[\"val_loss\"]\n",
    "    train_acc = model.history.history[\"acc\"]\n",
    "    valid_acc = model.history.history[\"val_acc\"]\n",
    "    \n",
    "    exp_name_tag = \"BATCH_SIZEt_EXP-%s\" % str(BATCH_SIZE)\n",
    "    results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                             'valid-loss': valid_loss,\n",
    "                             'train-acc': train_acc,\n",
    "                             'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
